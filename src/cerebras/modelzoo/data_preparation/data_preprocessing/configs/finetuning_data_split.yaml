##############################################################
## Autoregressive LM Preprocessing Parameters
##############################################################

setup:
    data:
        source: /path/to/text_data
        type: "local"  
    data_splits_dir:  /path/to/raw_data_splits_dir
    mode: "finetuning"
    output_dir: /path/to/output_dir
    processes: 1

    data_splits: 
        train : 
           split_fraction: 0.8
        val : 
           split_fraction: 0.2

processing:
    huggingface_tokenizer: "tiiuae/falcon-7b"

    max_seq_length: 2048
    short_seq_prob: 0.0
    write_in_batch: True
    
    resume_from_checkpoint: False
    seed: 0

    read_hook: "cerebras.modelzoo.data_preparation.data_preprocessing.hooks:prompt_completion_text_read_hook"
    read_hook_kwargs:
        prompt_key: <prompt_key>
        completion_key: <completion_key>

    shuffle_seed: 0
    shuffle: False
    
    use_ftfy: True
    ftfy_normalizer: "NFC"
    wikitext_detokenize: False

    UNSAFE_skip_jsonl_decoding_errors: False
    read_chunk_size: 64


    