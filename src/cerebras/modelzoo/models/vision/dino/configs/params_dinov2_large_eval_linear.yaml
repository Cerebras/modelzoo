# This file is generated by convert_dinov2_to_vit.py
# --input_config: params_dinov2_large_patch16_img224_cszoov2.yaml
#
# This is a config for doing downstream evaluation of a DINOv2 model trained on ImageNet-1K.
# For evaluation, we use a linear classifier trained on top of the frozen features of the DINOv2 model.
# We leverage VitClassification model from the modelzoo to train the linear classifier.
# The linear classifier is trained using the same data augmentation and normalization as the DINOv2 source repo.
# The hyperparameters like learning rate and batch size are set to produce eval 
# accuracy of ~81% on ImageNet-1K validation set, starting from the trained backbone 
# using dinov2 recipe in the modelzoo.

trainer:
  init:
    backend:
      backend_type: CSX
      cluster_config:
        num_csx: 1
        num_workers_per_csx: 2
    model:
      name: vision_transformer
      num_classes: 1000
      compute_eval_metrics: true
      use_bias_in_output: true
      use_dinov2_classifier: true
      freeze:
      - ^vit_model
      position_embedding_type: learned
      hidden_size: 1024
      use_post_embed_layer_norm: false
      use_embed_proj_bias: true
      num_hidden_layers: 24
      layer_norm_epsilon: 1.0e-06
      layerscale_value: 0.01
      num_heads: 16
      attention_type: scaled_dot_product
      attention_softmax_fp32: true
      nonlinearity: gelu
      use_projection_bias_in_attention: true
      use_ffn_bias_in_attention: true
      filter_size: 4096
      use_ffn_bias: true
      norm_first: true
      image_size:
      - 224
      - 224
      num_channels: 3
      patch_size:
      - 16
      - 16
      use_conv_patchified_embedding: false
      use_encoder_pooler_layer: false
      prepend_cls_token: true
    optimizer:
      SGD:
        momentum: 0.9
        weight_decay: 0.0
    schedulers:
    - SequentialLR:
        schedulers:
        - CosineAnnealingLR:
            initial_learning_rate: 0.025
            eta_min: 0.0
            T_max: 12500
    precision:
      enabled: true
      fp16_type: cbfloat16
      loss_scaling_factor: dynamic
      max_gradient_norm: 1.0
      precision_opt_level: 1
      log_loss_scale: true
    loop:
      max_steps: 12500
      eval_frequency: 12500
    checkpoint:
      steps: 12500
    logging:
      log_steps: 1
  fit:
    train_dataloader:
      data_processor: ImageNet1KProcessor
      data_dir: ./computer_vision/datasets/imagenet/imagenet1k_ilsvrc2012
      batch_size: 128
      image_size:
      - 224
      - 224
      shuffle: true
      shuffle_seed: 42
      split: train
      transforms:
      - name: random_resized_crop
        size:
        - 224
        - 224
        scale:
        - 0.08
        - 1.0
        ratio:
        - 0.75
        - 1.33
        interpolation: bicubic
      - name: random_horizontal_flip
        p: 0.5
      - name: to_tensor
      - name: normalize
        mean:
        - 0.485
        - 0.456
        - 0.406
        std:
        - 0.229
        - 0.224
        - 0.225
      num_workers: 8
      prefetch_factor: 2
      persistent_workers: true
      use_worker_cache: true
    val_dataloader:
      data_processor: ImageNet1KProcessor
      data_dir: ./computer_vision/datasets/imagenet/imagenet1k_ilsvrc2012
      batch_size: 128
      image_size:
      - 224
      - 224
      split: val
      transforms:
      - name: resize
        size:
        - 256
        - 256
        interpolation: bicubic
      - name: center_crop
        size:
        - 224
        - 224
      - name: to_tensor
      - name: normalize
        mean:
        - 0.485
        - 0.456
        - 0.406
        std:
        - 0.229
        - 0.224
        - 0.225
      num_workers: 8
      prefetch_factor: 2
      persistent_workers: true
      use_worker_cache: true
