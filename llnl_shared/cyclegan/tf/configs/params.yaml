base: &base
    train_input:
        batch_size: 8
        data_directory: '/cb/data/llnl/cyclegan/'
        image_filename: 'jag10K_images.npy'
        scalar_filename: 'jag10K_0_scalars.npy'
        input_filename: 'jag10K_params.npy'
        embeddings_filename: 'jag10K_embeddings_test.npy'
        random_seed: 4321 #this is the random seed used during training.
        prefetch_size: 3

    runconfig:
        model_dir: "model_dir"
        save_summary_steps: 50
        save_checkpoints_steps: 100
        log_step_count_steps: 50
        keep_checkpoint_max: 2
        cs_ip: null
        max_steps: 500

    optimizer:
        learning_rate: .0001
        optimizer: "adam"

    model:
        mixed_precision: True
        forward:
            model_name: 'forward'
            input_size: 5
            output_size: 20
            hidden_sizes: [32, 256, 1024]
            activations: ['relu', 'relu', 'relu', null]
            input_names: ['inputs']
            output_names: ['latent_tensors']
            use_fp32_loss: False

        inverse:
            model_name: 'inverse'
            input_size: 20
            output_size: 5
            hidden_sizes: [16, 128, 512]
            activations: ['relu', 'relu', 'relu', null]
            input_names: ['latent_tensors']
            output_names: ['inputs']
            use_fp32_loss: False

        decoder:
            model_name: 'decoder'
            input_size: 20
            output_size: 16399
            hidden_sizes: [16, 128, 512]
            activations: ['relu', 'relu', 'relu', null]
            input_names: ['latent_tensors']
            output_names: ['images', 'scalars']
            use_fp32_loss: True

        encoder:
            model_name: 'encoder'
            input_size: 16399
            output_size: 20
            hidden_sizes: [32, 256, 128]
            # activations: ['elu', 'tanh', 'tanh', null]
            activations: ['tanh', 'tanh', 'tanh', null]
            input_names: ['images', 'scalars']
            output_names: ['latent_tensors']
            use_fp32_loss: False

        discriminator:
            model_name: 'discriminator'
            input_size: 25
            output_size: 1
            hidden_sizes: [1024, 256, 256]
            #activations: ['leaky_relu', 'leaky_relu', 'leaky_relu', null]
            activations: ['relu', 'relu', 'relu', null]
            input_names: ['latent_tensors', 'inputs']
            output_names: ['adv_labels']
            use_fp32_loss: False
